# AmaniQuery ğŸ‡°ğŸ‡ª

A Retrieval-Augmented Generation (RAG) system for Kenyan legal, parliamentary, and news intelligence.

## ğŸ›ï¸ Architecture

AmaniQuery is built as a 4-module pipeline:

1. **NiruSpider** - Web crawler for data ingestion
2. **NiruParser** - ETL pipeline with embedding generation
3. **NiruDB** - Vector database with metadata storage
4. **NiruAPI** - RAG-powered query interface

## ğŸ“‚ Project Structure

```
AmaniQuery/
â”œâ”€â”€ Module1_NiruSpider/          # Data crawling & ingestion
â”‚   â”œâ”€â”€ spiders/
â”‚   â”‚   â”œâ”€â”€ kenya_law_spider.py
â”‚   â”‚   â”œâ”€â”€ parliament_spider.py
â”‚   â”‚   â”œâ”€â”€ news_rss_spider.py
â”‚   â”‚   â””â”€â”€ global_trends_spider.py
â”‚   â”œâ”€â”€ scrapy.cfg
â”‚   â””â”€â”€ settings.py
â”œâ”€â”€ Module2_NiruParser/          # ETL & embedding pipeline
â”‚   â”œâ”€â”€ extractors/
â”‚   â”œâ”€â”€ cleaners/
â”‚   â”œâ”€â”€ chunkers/
â”‚   â””â”€â”€ embedders/
â”œâ”€â”€ Module3_NiruDB/              # Vector database
â”‚   â”œâ”€â”€ vector_store.py
â”‚   â””â”€â”€ metadata_manager.py
â”œâ”€â”€ Module4_NiruAPI/             # RAG API
â”‚   â”œâ”€â”€ api.py
â”‚   â”œâ”€â”€ rag_pipeline.py
â”‚   â””â”€â”€ models/
â”œâ”€â”€ data/                        # Data storage
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ embeddings/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ sources.yaml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### 1. Installation

```bash
# Create virtual environment
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt
```

### 2. Configuration

```bash
# Copy environment template
cp .env.example .env

# Edit .env with your settings
```

### 3. Run Modules

```bash
# Module 1: Crawl data
python -m Module1_NiruSpider.crawl_all

# Module 2: Process & embed data
python -m Module2_NiruParser.process_pipeline

# Module 3: Initialize database (automatic)

# Module 4: Start API server
python -m Module4_NiruAPI.api
```

## ğŸ¯ Data Sources

### Kenyan Laws & Constitution
- **Source**: http://kenyalaw.org/
- **Strategy**: One-time crawl + periodic updates
- **Content**: Acts of Parliament, Constitution

### Parliament
- **Source**: https://www.parliament.go.ke/
- **Strategy**: Weekly crawl
- **Content**: Hansards, Bills, Publications

### Kenyan News (High-Frequency)
- **Sources**: 
  - nation.africa/rss
  - standardmedia.co.ke/rss
  - the-star.co.ke/rss
  - businessdailyafrica.com/rss
- **Strategy**: Daily RSS feed parsing

### Global Trends
- **Sources**:
  - Reuters (Technology/World)
  - TechCrunch
  - Al Jazeera (Politics)
- **Strategy**: Daily RSS feed parsing

## ğŸ§  RAG Pipeline

1. **Chunking**: 500-1000 characters with 100-char overlap
2. **Embedding Model**: all-MiniLM-L6-v2
3. **Vector DB**: ChromaDB / FAISS
4. **LLM**: Configurable (OpenAI, Anthropic, Local)

## ğŸ“Š Metadata Structure

Each chunk stores:
- `source_url`: Original article/document URL
- `title`: Document title
- `publication_date`: ISO format date
- `category`: ["Kenyan Law", "Parliament", "Kenyan News", "Global Trend"]
- `chunk_id`: Unique identifier (e.g., article-xyz_chunk_3)
- `author`: When available
- `summary`: Auto-generated snippet

## ğŸ”§ Configuration

Edit `config/sources.yaml` to:
- Add/remove data sources
- Adjust crawl schedules
- Configure chunk sizes
- Set embedding parameters

## ğŸ“… Automated Scheduling

Use Windows Task Scheduler or cron (Linux):

```bash
# Daily news crawl at 6 AM
# Weekly parliament crawl on Mondays
# Monthly law database update
```

See `scripts/scheduler_setup.md` for details.

## ğŸ›¡ï¸ Ethical Crawling

- Respects `robots.txt`
- 2-3 second delays between requests
- User-agent identification
- Rate limiting on RSS feeds

## ğŸ“ License

MIT License - See LICENSE file

## ğŸ¤ Contributing

This is a hackathon project. Contributions welcome!

---

**Built with â¤ï¸ for Kenya**
